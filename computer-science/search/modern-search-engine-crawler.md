# 构建现代搜索引擎（一）——爬虫

<!--
ID: c94ff450-9415-4404-991a-2583a5c2b480
Status: draft
Date: 2018-09-05T02:10:00
Modified: 2020-05-16T11:23:32
wp_id: 473
-->

搜索引擎的几个必备组件:

爬虫, 索引, 排序, 日志分析

搜索服务展现的前后几个步骤为: 召回 -> 过滤 -> 排序

最近在看斯坦福大学的 *Introduction to IR* 一书，作为信息检索领域的权威之作，这本书在豆瓣上的评价高达 9.1 分，可见其含金量。

搜索引擎产品经理的日常: https://www.douban.com/note/693904092/
搜索引擎 Query Analysis: https://www.jishuwen.com/d/2VHD

该书成书于 2007 年左右，随着这十多年种开源软件的发展，书中的一些算法或者是系统已经都是很常见的基础设施。所以在现在来说，要想按照书中的介绍搭建一套简单的搜索系统，应该不是难事，下面从我最熟悉的爬虫开始。

# 要点

## 采集器的功能特点

1. 稳健性（不会陷入爬虫陷阱，无限循环）
2. 礼貌性（能够遵守 robots.txt）
3. 分布式
4. 横向可扩展性，简单来说就是可以通过增加设备横向扩展
5. 性能好
6. 质量高，优先抓取高质量网页，避开垃圾网页
7. 新鲜度，应该在网页更新后尽快抓取
8. 可扩展性，能够处理新的数据格式、协议等

## 架构

1. URL Frontier，待抓取的 URL 池
2. DNS
3. 抓取模块
4. 解析模块
5. URL 去重模块

![架构图]()

# 实现

按照上面的架构组件，我们一共需要实现五部分，下面一一讲解

## URL Frontier

这个组件中持有待抓取的URL，实际上是一个调度的模块，

## DNS 模块

系统解析域名的时候需要调用远程的 DNS 服务器，而如果远程的 DNS 服务器上没有相关的记录缓存，还需要再递归调用上一级的 DNS 服务器，因此这个过程很可能是一个很费时的过程。由于内核中也没有 DNS 解析的缓存机制，所以每次解析都会请求一次网络。有下面几种思路来解决这个问题

1. 在程序中缓存 DNS 结果，比如说使用一个字典来存一下 域名-IP 的记录
2. 在本机安装 DNS 服务器
